{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Graident_descent_scratch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3bWn7A-WF80"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "of9RGsvhWKlT"
      },
      "source": [
        "def gradient_descent(x,y,iterations):\n",
        "\n",
        "  m=c=0               #coef. and intercept\n",
        "  alpha=0.001         #learning rate\n",
        "  n = len(x)\n",
        "  \n",
        "  for num in range(iterations):\n",
        "    \n",
        "    y_pred = m*x + c\n",
        "   \n",
        "    loss = 1/n * sum(pow((y-y_pred),2))  #Cost function for linear regression\n",
        "\n",
        "    m_change = -(2/n)*sum(x*(y-y_pred))   \n",
        "  \n",
        "\n",
        "    c_change = -(2/n)*sum((y-y_pred))\n",
        "\n",
        "    \n",
        "    m = m - (alpha*m_change)\n",
        "    c = c - (alpha*c_change)\n",
        "\n",
        "    if num%10==0:\n",
        "      print(\"m: {}, c: {}, loss: {}\".format(m,c,loss))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iODUBnlCX0XJ"
      },
      "source": [
        "x = np.array([1,2,3,4,5])\n",
        "y = np.array([5,7,9,11,13])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7vaoFw0K6we",
        "outputId": "6c59f729-ca3d-4b97-f9c0-733fb7f435fc"
      },
      "source": [
        " gradient_descent(x,y,1000)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "m: 0.062, c: 0.018000000000000002, loss: 89.0\n",
            "m: 0.606524096911324, c: 0.17707902249404894, loss: 55.481997572035766\n",
            "m: 1.0346467946173648, c: 0.30388885791401476, loss: 34.716978058642574\n",
            "m: 1.3711572665200158, c: 0.4052958038672161, loss: 21.85178165176719\n",
            "m: 1.6355658279397605, c: 0.48670399860161645, loss: 13.880129099104792\n",
            "m: 1.8432280686490217, c: 0.552366787693111, loss: 8.939787238064742\n",
            "m: 2.0062296014489602, c: 0.6056317852153791, loss: 5.877199735111256\n",
            "m: 2.1340824035891144, c: 0.6491337491483191, loss: 3.9777985569723064\n",
            "m: 2.2342728723228524, c: 0.6849463839798712, loss: 2.7989460059773794\n",
            "m: 2.312693172064651, c: 0.7147018169529653, loss: 2.066451032105658\n",
            "m: 2.37398072619568, c: 0.7396846318529557, loss: 1.6104664905993602\n",
            "m: 2.421785414109416, c: 0.7609058783057873, loss: 1.3257808394957686\n",
            "m: 2.458979868662134, c: 0.7791613208006972, loss: 1.1472209191919231\n",
            "m: 2.487824990793697, c: 0.7950772835871841, loss: 1.0344152584634663\n",
            "m: 2.510100217819589, c: 0.8091467329040799, loss: 0.9623557379611971\n",
            "m: 2.527206051097798, c: 0.8217576755002777, loss: 0.9155510334653217\n",
            "m: 2.5402447504350527, c: 0.8332155096923523, loss: 0.8844049791929003\n",
            "m: 2.5500838446239626, c: 0.8437606167659836, loss: 0.8629731529276499\n",
            "m: 2.557406117414976, c: 0.8535822062896871, loss: 0.8475731976194956\n",
            "m: 2.5627489489785087, c: 0.8628292130700038, loss: 0.835923988158342\n",
            "m: 2.5665352796049934, c: 0.8716188736009273, loss: 0.8266123901252691\n",
            "m: 2.5690979796867666, c: 0.8800434761591291, loss: 0.8187629446720237\n",
            "m: 2.570699030113706, c: 0.8881756734670041, loss: 0.8118332555433861\n",
            "m: 2.5715446182046993, c: 0.8960726640246307, loss: 0.8054872420148721\n",
            "m: 2.5717970189613397, c: 0.9037794830275349, loss: 0.7995166257000597\n",
            "m: 2.5715839462092975, c: 0.9113315924839049, loss: 0.7937922957221788\n",
            "m: 2.5710059124146394, c: 0.9187569197666953, loss: 0.7882341819725851\n",
            "m: 2.5701420212276362, c: 0.926077462056374, loss: 0.7827925931629052\n",
            "m: 2.569054526504662, c: 0.9333105491178755, loss: 0.7774366567183574\n",
            "m: 2.567792420486595, c: 0.9404698371694692, loss: 0.7721471578909749\n",
            "m: 2.5663942578747845, c: 0.9475660911075047, loss: 0.76691210395993\n",
            "m: 2.564890378520156, c: 0.954607800156633, loss: 0.7617239764810667\n",
            "m: 2.563304656790752, c: 0.9616016624175439, loss: 0.756578029194841\n",
            "m: 2.561655878411502, c: 0.9685529662304784, loss: 0.7514712336650784\n",
            "m: 2.559958824105993, c: 0.9754658903275967, loss: 0.7464016261531792\n",
            "m: 2.55822512247674, c: 0.9823437400681049, loss: 0.7413679030367701\n",
            "m: 2.5564639212645965, c: 0.9891891333673128, loss: 0.7363691701886959\n",
            "m: 2.5546824156634655, c: 0.9960041470323003, loss: 0.7314047877264234\n",
            "m: 2.552886264130369, c: 1.0027904319355967, loss: 0.7264742738384729\n",
            "m: 2.5510799156487374, c: 1.0095493036628216, loss: 0.7215772452059939\n",
            "m: 2.549266867300948, c: 1.0162818138570988, loss: 0.7167133800931762\n",
            "m: 2.5474498669907604, c: 1.022988806370869, loss: 0.711882395479814\n",
            "m: 2.5456310729959606, c: 1.0296709614603625, loss: 0.7070840328923111\n",
            "m: 2.543812179544236, c: 1.0363288305690435, loss: 0.702318049622908\n",
            "m: 2.5419945156476222, c: 1.0429628637041057, loss: 0.6975842132866856\n",
            "m: 2.5401791228901103, c: 1.0495734309833307, loss: 0.6928822984461548\n",
            "m: 2.5383668166503344, c: 1.0561608395937236, loss: 0.6882120845166418\n",
            "m: 2.5365582342868422, c: 1.0627253471389897, loss: 0.6835733544650813\n",
            "m: 2.5347538730622685, c: 1.0692671721448495, loss: 0.6789658940003037\n",
            "m: 2.5329541199915035, c: 1.0757865023274273, loss: 0.674389491067819\n",
            "m: 2.5311592753336476, c: 1.0822835011010656, loss: 0.6698439355332253\n",
            "m: 2.529369571081307, c: 1.0887583127004823, loss: 0.6653290189824967\n",
            "m: 2.5275851855125446, c: 1.095211066212341, loss: 0.6608445345946915\n",
            "m: 2.5258062546439426, c: 1.1016418787484787, loss: 0.6563902770595531\n",
            "m: 2.524032881244691, c: 1.10805085794357, loss: 0.651966042522925\n",
            "m: 2.522265141931074, c: 1.114438103921094, loss: 0.6475716285494446\n",
            "m: 2.52050309275014, c: 1.120803710840821, loss: 0.6432068340959421\n",
            "m: 2.5187467735742772, c: 1.1271477681169404, loss: 0.6388714594915043\n",
            "m: 2.5169962115599196, c: 1.133470361376962, loss: 0.6345653064216896\n",
            "m: 2.515251423869671, c: 1.1397715732165945, loss: 0.630288177915336\n",
            "m: 2.5135124198147065, c: 1.1460514837940459, loss: 0.6260398783330002\n",
            "m: 2.511779202540902, c: 1.1523101712979422, loss: 0.6218202133564238\n",
            "m: 2.5100517703558505, c: 1.1585477123157724, loss: 0.6176289899786703\n",
            "m: 2.508330117773248, c: 1.1647641821240486, loss: 0.6134660164946901\n",
            "m: 2.506614236334828, c: 1.170959654916847, loss: 0.6093311024921714\n",
            "m: 2.504904115257217, c: 1.1771342039858526, loss: 0.605224058842603\n",
            "m: 2.503199741940995, c: 1.1832879018622302, loss: 0.6011446976924782\n",
            "m: 2.501501102371305, c: 1.18942082042846, loss: 0.5970928324546109\n",
            "m: 2.4998081814331083, c: 1.1955330310065198, loss: 0.5930682777995483\n",
            "m: 2.498120963159255, c: 1.201624604427464, loss: 0.5890708496470605\n",
            "m: 2.4964394309256828, c: 1.2076956110863502, loss: 0.5851003651576958\n",
            "m: 2.494763567605006, c: 1.2137461209856353, loss: 0.5811566427244118\n",
            "m: 2.493093355687344, c: 1.2197762037695041, loss: 0.5772395019642492\n",
            "m: 2.491428777375379, c: 1.225785928751045, loss: 0.5733487637100884\n",
            "m: 2.4897698146591254, c: 1.2317753649338103, loss: 0.5694842500024427\n",
            "m: 2.488116449374726, c: 1.2377445810289494, loss: 0.5656457840813216\n",
            "m: 2.486468663250689, c: 1.2436936454688567, loss: 0.5618331903781429\n",
            "m: 2.4848264379442275, c: 1.2496226264180796, loss: 0.5580462945076999\n",
            "m: 2.483189755069817, c: 1.2555315917820653, loss: 0.5542849232601883\n",
            "m: 2.481558596221629, c: 1.2614206092142082, loss: 0.5505489045932802\n",
            "m: 2.4799329429911405, c: 1.2672897461215595, loss: 0.5468380676242578\n",
            "m: 2.4783127769809443, c: 1.2731390696694849, loss: 0.5431522426221947\n",
            "m: 2.4766980798155838, c: 1.2789686467854855, loss: 0.5394912610001923\n",
            "m: 2.475088833150026, c: 1.2847785441623747, loss: 0.5358549553076719\n",
            "m: 2.4734850186762896, c: 1.2905688282609316, loss: 0.5322431592227116\n",
            "m: 2.471886618128622, c: 1.2963395653121519, loss: 0.5286557075444426\n",
            "m: 2.4702936132875206, c: 1.30209082131918, loss: 0.5250924361854893\n",
            "m: 2.4687059859828615, c: 1.307822662058985, loss: 0.521553182164468\n",
            "m: 2.4671237180963135, c: 1.313535153083841, loss: 0.5180377835985295\n",
            "m: 2.4655467915631966, c: 1.3192283597226486, loss: 0.5145460796959531\n",
            "m: 2.4639751883739023, c: 1.3249023470821317, loss: 0.5110779107487983\n",
            "m: 2.4624088905749657, c: 1.3305571800479365, loss: 0.5076331181255923\n",
            "m: 2.4608478802698657, c: 1.336192923285652, loss: 0.504211544264081\n",
            "m: 2.459292139619614, c: 1.3418096412417688, loss: 0.5008130326640182\n",
            "m: 2.4577416508431753, c: 1.34740739814459, loss: 0.4974374278800074\n",
            "m: 2.4561963962177544, c: 1.3529862580051004, loss: 0.49408457551439267\n",
            "m: 2.4546563580789793, c: 1.3585462846178058, loss: 0.49075432221019927\n",
            "m: 2.453121518821003, c: 1.364087541561546, loss: 0.487446515644114\n",
            "m: 2.4515918608965435, c: 1.36961009220029, loss: 0.4841610045195226\n",
            "m: 2.450067366816869, c: 1.3751139996839103, loss: 0.48089763855958734\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}